{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#Resnet-50 model was created in majority by Angel Picon with specific help from Leonel Torres on the loading cov images with label as he figured this section out\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# google drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset Class\n",
        "class COVIDDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "\n",
        "        # Directory for images\n",
        "        covid_folder = \"/content/drive/MyDrive/Cov19 Dataset/Early Cov\"\n",
        "        non_covid_folder = \"/content/drive/MyDrive/Cov19 Dataset/Control\"\n",
        "\n",
        "        # Load COV images Label 1\n",
        "        for img in os.listdir(covid_folder):\n",
        "            if img.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                self.samples.append((os.path.join(covid_folder, img), 1))\n",
        "\n",
        "        # Load NON-COV images label 0\n",
        "        for img in os.listdir(non_covid_folder):\n",
        "            if img.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                self.samples.append((os.path.join(non_covid_folder, img), 0))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Transform to 224\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Resnet model\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)  # Binary classification\n",
        "model = model.to(device)\n",
        "\n",
        "# Training the model\n",
        "def train(dataloader, epochs=3):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}/{epochs} complete\")\n",
        "\n",
        "# Model Evaluation\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds,\n",
        "                              target_names=[\"Non-COVID\", \"COVID\"]))\n",
        "\n",
        "# 8. Main Execution\n",
        "if __name__ == \"main\":\n",
        "    # Create dataset\n",
        "    dataset = COVIDDataset(transform=transform)\n",
        "\n",
        "    # 80 20 dataset split\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    train_set, test_set = torch.utils.data.random_split(dataset, [train_size, len(dataset)-train_size])\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=16)\n",
        "\n",
        "    # Train and evaluate\n",
        "    train(train_loader)\n",
        "    evaluate(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCUt_Dq-6fH-",
        "outputId": "8567a48a-af1b-4a6b-b937-75ee75244172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 1/3 complete\n",
            "Epoch 2/3 complete\n",
            "Epoch 3/3 complete\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-COVID       1.00      0.81      0.90       106\n",
            "       COVID       0.82      1.00      0.90        94\n",
            "\n",
            "    accuracy                           0.90       200\n",
            "   macro avg       0.91      0.91      0.90       200\n",
            "weighted avg       0.92      0.90      0.90       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "\n",
        "#main implementation remained the same so same code written by Angel Picon. Leonel introduced the idea of using Random Forrest after our presentation so the random forrest implementation was written by him.\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Same implementation as previous\n",
        "class COVIDDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "\n",
        "        covid_folder = \"/content/drive/MyDrive/Cov19 Dataset/Early Cov\"\n",
        "        non_covid_folder = \"/content/drive/MyDrive/Cov19 Dataset/Control\"\n",
        "\n",
        "        for img in os.listdir(covid_folder):\n",
        "            if img.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                self.samples.append((os.path.join(covid_folder, img), 1))\n",
        "\n",
        "        for img in os.listdir(non_covid_folder):\n",
        "            if img.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                self.samples.append((os.path.join(non_covid_folder, img), 0))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# 80-20 data split\n",
        "dataset = COVIDDataset(transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
        "\n",
        "# Declaring feature extractions\n",
        "feature_extractor = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "feature_extractor = nn.Sequential(*list(feature_extractor.children())[:-1])\n",
        "feature_extractor = feature_extractor.to(device)\n",
        "feature_extractor.eval()\n",
        "\n",
        "# Function for creating features including flatten which is neccesary in Random forrest\n",
        "def extract_features(dataset):\n",
        "    loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in tqdm(loader, desc=\"Extracting Features\"):\n",
        "            imgs = imgs.to(device)\n",
        "            out = feature_extractor(imgs)\n",
        "            out = out.view(out.size(0), -1)  #\n",
        "            features.append(out.cpu().numpy())\n",
        "            labels.extend(lbls)\n",
        "\n",
        "    return np.concatenate(features), np.array(labels)\n",
        "\n",
        "# Extract features to train sets\n",
        "X_train_feat, y_train = extract_features(train_set)\n",
        "X_test_feat, y_test = extract_features(test_set)\n",
        "\n",
        "# Training random forrest as stolen from previous lectures\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_feat, y_train)\n",
        "\n",
        "# Evaluation report\n",
        "y_pred = rf_model.predict(X_test_feat)\n",
        "print(\"\\n=== Random Forest Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Non-COVID\", \"COVID\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0TVVHub7c1k",
        "outputId": "4eb0275a-b0fc-4b55-84bf-2f9f1b65a844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 177MB/s]\n",
            "Extracting Features: 100%|██████████| 50/50 [02:41<00:00,  3.23s/it]\n",
            "Extracting Features: 100%|██████████| 13/13 [00:41<00:00,  3.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Random Forest Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-COVID       0.78      0.77      0.78        99\n",
            "       COVID       0.78      0.79      0.78       101\n",
            "\n",
            "    accuracy                           0.78       200\n",
            "   macro avg       0.78      0.78      0.78       200\n",
            "weighted avg       0.78      0.78      0.78       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#The base code all the way up to the ModelEVAL function was created by Angel Picon. Everything past ModelEval was written by Leonel Torres\n",
        "\n",
        "        # Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Mount drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class XRayIMGDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Direct paths to our dataset folders\n",
        "        covid_dir = \"/content/drive/MyDrive/Cov19 Dataset/Early Cov\"\n",
        "        normal_dir = \"/content/drive/MyDrive/Cov19 Dataset/Control\"\n",
        "\n",
        "        # Find Positive covid-19 xray images ending with png, jpg, jpeg\n",
        "        cov_files = [f for f in os.listdir(covid_dir) if f.lower().endswith(('png','jpg','jpeg'))]\n",
        "        random.shuffle(cov_files)\n",
        "        for img in cov_files[:500]:  # Temp limit of files for max number of files in folder\n",
        "            self.image_paths.append(os.path.join(covid_dir, img))\n",
        "            self.labels.append(1)  # Label is 1 for positive cases\n",
        "\n",
        "        # Find negative covid-19 xray images ending with png, jpg, jpeg\n",
        "        print(f\"{datetime.now().strftime('%H:%M')} - Loading normal images...\")\n",
        "        norm_files = [f for f in os.listdir(normal_dir) if f.lower().endswith(('png','jpg','jpeg'))]\n",
        "        random.shuffle(norm_files)\n",
        "        for img in norm_files[:500]:   # Temp limit of files for max number of files in folder\n",
        "            self.image_paths.append(os.path.join(normal_dir, img))\n",
        "            self.labels.append(0)  # Label is 2 for negative cases\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        try:\n",
        "            # Convert to grayscale for Otsu thresholding\n",
        "            img = Image.open(img_path).convert('L')\n",
        "            img_np = np.array(img)\n",
        "\n",
        "            # Apply Otsu thresholding\n",
        "            thresh = cv2.adaptiveThreshold(\n",
        "    img_np, 255,\n",
        "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C, #guasian blur to higk\n",
        "    cv2.THRESH_BINARY, 11, 2\n",
        ")\n",
        "\n",
        "            # Convert back to RGB for ResNet\n",
        "            img_rgb = cv2.cvtColor(thresh, cv2.COLOR_GRAY2RGB)\n",
        "            img_pil = Image.fromarray(img_rgb)\n",
        "\n",
        "            # Resize and convert to tensor\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "            img = transform(img_pil)\n",
        "\n",
        "            return img, self.labels[idx]\n",
        "        except Exception as e:\n",
        "            return torch.zeros(3, 224, 224), 0  # Return blank image if error\n",
        "\n",
        "# Use ResNet50 model\n",
        "try:\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(model.fc.in_features, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(256, 2)  # Binary implmentation\n",
        "    )\n",
        "    model = model.to(device)\n",
        "except Exception as e:\n",
        "    raise\n",
        "\n",
        "# Training model using CrossEntropy and 3 epochs\n",
        "def Model_TRAIN(data_loader, epochs=3):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(data_loader):\n",
        "                if images is None:\n",
        "                    continue\n",
        "\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                #Training the model\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                batch_count += 1\n",
        "\n",
        "                #check with model after each round to ensure model is learning (Decrease in average loss)\n",
        "                if batch_idx % 30 == 0:\n",
        "                    avg_loss = total_loss / batch_count\n",
        "                    print(f\"{datetime.now().strftime('%H:%M')} - Batch {batch_idx} | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "def Model_EVAL(data_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(data_loader):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                if batch_idx % 20 == 0:\n",
        "                    print(f\"{datetime.now().strftime('%H:%M')} - Evaluated batch {batch_idx}\")\n",
        "\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(all_labels, all_preds, target_names=[\"Normal\", \"COVID\"]))\n",
        "    except Exception as e:\n",
        "        print(f\"{datetime.now().strftime('%H:%M')} - Evaluation failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    try:\n",
        "        # Load and prepare dataset\n",
        "        dataset = XRayIMGDataset()\n",
        "\n",
        "        # Split into training and test sets\n",
        "        train_size = int(0.8 * len(dataset))\n",
        "        test_size = len(dataset) - train_size\n",
        "        train_set, test_set = torch.utils.data.random_split(\n",
        "            dataset,\n",
        "            [train_size, test_size]\n",
        "        )\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader = DataLoader(train_set, batch_size=12, shuffle=True)\n",
        "        test_loader = DataLoader(test_set, batch_size=12)\n",
        "\n",
        "        # Train the model\n",
        "        Model_TRAIN(train_loader, epochs=3)\n",
        "\n",
        "        # Evaluate performance\n",
        "        Model_EVAL(test_loader)\n",
        "\n",
        "        #error handling in case cannot find dataset\n",
        "    except Exception as e:\n",
        "        print(f\"\\n{datetime.now().strftime('%H:%M')} - Critical error: {str(e)}\")\n",
        "    finally:\n",
        "        print(f\"\\n{datetime.now().strftime('%H:%M')} - Execution complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX7knwMQBTHU",
        "outputId": "26c6c0a1-9874-468c-fd06-02a4d4840634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "02:08 - Loading normal images...\n",
            "02:08 - Batch 0 | Loss: 0.7242\n",
            "02:08 - Batch 30 | Loss: 0.5681\n",
            "02:08 - Batch 60 | Loss: 0.4741\n",
            "02:08 - Evaluated batch 0\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.85      0.95      0.90        96\n",
            "       COVID       0.95      0.85      0.89       104\n",
            "\n",
            "    accuracy                           0.90       200\n",
            "   macro avg       0.90      0.90      0.89       200\n",
            "weighted avg       0.90      0.90      0.89       200\n",
            "\n",
            "\n",
            "02:08 - Execution complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XSJN-0sxMFbL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}